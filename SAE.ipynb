{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddd466-fd18-4b9a-8b66-91f501d974e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers, applications\n",
    "import os, random, pathlib\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "IMG_RES    = 256\n",
    "BATCH      = 16\n",
    "MAX_IMAGES = None\n",
    "AUTOTUNE   = tf.data.AUTOTUNE\n",
    "\n",
    "img_root = kagglehub.dataset_download(\"sivarazadi/wikiart-art-movementsstyles\")\n",
    "\n",
    "patterns = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "files = []\n",
    "for pat in patterns:\n",
    "    files += pathlib.Path(img_root).rglob(pat)\n",
    "\n",
    "if not files:\n",
    "    raise RuntimeError(f\"No images found under {img_root}\")\n",
    "\n",
    "random.shuffle(files)\n",
    "if MAX_IMAGES is not None:\n",
    "    files = files[:MAX_IMAGES]\n",
    "\n",
    "print(f\"Using {len(files):,} total images.\")\n",
    "\n",
    "paths_ds = tf.data.Dataset.from_tensor_slices([str(p) for p in files])\n",
    "\n",
    "def decode(path):\n",
    "    img  = tf.io.read_file(path)\n",
    "    img  = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img  = tf.image.random_flip_left_right(img)\n",
    "    img  = tf.image.resize(img, [IMG_RES, IMG_RES])\n",
    "    img  = (img / 127.5) - 1.0\n",
    "    return img\n",
    "\n",
    "dataset = (paths_ds\n",
    "           .map(decode, num_parallel_calls=AUTOTUNE)\n",
    "           .apply(tf.data.experimental.ignore_errors())\n",
    "           .shuffle(min(len(files), 8_000))\n",
    "           .batch(BATCH, drop_remainder=True)\n",
    "           #.cache()                   \n",
    "           .repeat()\n",
    "           .prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bda0e9-5b0b-4b6f-8395-d4530de21361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers, applications\n",
    "import os, random, pathlib\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "IMG     = 256\n",
    "BATCH   = 16\n",
    "LATENT  = 2048\n",
    "STR_CH  = 16\n",
    "LAMBDA_L1 = 5.0\n",
    "LAMBDA_PERCEP = 1.0\n",
    "LAMBDA_STYLE = 0.1\n",
    "\n",
    "# VGG model for perceptual loss\n",
    "def build_vgg_features():\n",
    "    vgg = applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    outputs = [vgg.get_layer(name).output for name in [\n",
    "        'block1_conv1', 'block2_conv1', \n",
    "        'block3_conv1', 'block4_conv1', \n",
    "        'block5_conv1'\n",
    "    ]]\n",
    "    return models.Model(vgg.input, outputs)\n",
    "\n",
    "# cbl with residual connection option\n",
    "def cbl(x, f, k=3, s=1, use_residual=False, name=None):\n",
    "    \"\"\"Conv → BatchNorm → LeakyReLU with optional residual connection.\"\"\"\n",
    "    skip = x\n",
    "    x = layers.Conv2D(f, k, s, 'same', use_bias=False, name=f'{name}_conv')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9, name=f'{name}_bn')(x)\n",
    "    x = layers.LeakyReLU(0.2, name=f'{name}_lrelu')(x)\n",
    "    \n",
    "    # Add residual connection if requested and shapes match\n",
    "    if use_residual and skip.shape[-1] == f and s == 1:\n",
    "        x = layers.Add(name=f'{name}_add')([x, skip])\n",
    "    return x\n",
    "\n",
    "# Enhanced AdaIN\n",
    "def adain(x, w, name=None):\n",
    "    \"\"\"Enhanced AdaIN with deeper MLP for style transformation.\"\"\"\n",
    "    # normalise x\n",
    "    mu, var = tf.nn.moments(x, [1,2], keepdims=True)\n",
    "    x_norm = (x - mu) / tf.sqrt(var + 1e-5)\n",
    "    \n",
    "    # Multi-layer style network for better feature modulation\n",
    "    style = layers.Dense(512, name=f'{name}_dense1')(w)\n",
    "    style = layers.LeakyReLU(0.2)(style)\n",
    "    style = layers.Dense(2 * x.shape[-1], name=f'{name}_dense2')(style)\n",
    "    \n",
    "    gamma, beta = tf.split(style, 2, axis=-1)\n",
    "    gamma = tf.reshape(gamma, [-1,1,1,x.shape[-1]])\n",
    "    beta = tf.reshape(beta, [-1,1,1,x.shape[-1]])\n",
    "    \n",
    "    return gamma * x_norm + beta\n",
    "\n",
    "def build_encoder():\n",
    "    inp = layers.Input([IMG, IMG, 3])\n",
    "    \n",
    "    # Initial conv\n",
    "    x = cbl(inp, 64, name='enc_c1')\n",
    "    \n",
    "    # Downsampling blocks with more capacity\n",
    "    x = cbl(x, 128, s=2, name='enc_c2')           # 128×128\n",
    "    x = cbl(x, 128, use_residual=True, name='enc_r2')\n",
    "    \n",
    "    x = cbl(x, 256, s=2, name='enc_c3')           # 64×64\n",
    "    x = cbl(x, 256, use_residual=True, name='enc_r3')\n",
    "    \n",
    "    x = cbl(x, 512, s=2, name='enc_c4')           # 32×32\n",
    "    x = cbl(x, 512, use_residual=True, name='enc_r4')\n",
    "    \n",
    "    # Add one more layer for better feature extraction\n",
    "    x = cbl(x, 512, use_residual=True, name='enc_r5')\n",
    "\n",
    "    # Structure code with more channels\n",
    "    structure = layers.Conv2D(STR_CH, 1, padding='same', name='structure')(x)  # 32×32×16\n",
    "    \n",
    "    # Texture code with enhanced feature extraction\n",
    "    texture_feat = layers.GlobalAveragePooling2D(name='gap')(x)\n",
    "    texture = layers.Dense(1024, activation='relu', name='texture_fc1')(texture_feat)\n",
    "    texture = layers.Dense(LATENT, name='texture')(texture)\n",
    "\n",
    "    return models.Model(inp, [structure, texture], name='Encoder')\n",
    "\n",
    "def build_generator():\n",
    "    s_in = layers.Input([None, None, STR_CH])\n",
    "    t_in = layers.Input([LATENT])\n",
    "    \n",
    "    # Initial processing with residual blocks\n",
    "    x = cbl(s_in, 512, k=3, name='gen_c0')\n",
    "    x = adain(x, t_in, 'gen_adain0')\n",
    "    x = cbl(x, 512, use_residual=True, name='gen_r0')\n",
    "    x = adain(x, t_in, 'gen_adain0b')\n",
    "\n",
    "    # Upsampling blocks with residual connections\n",
    "    for i, f in enumerate([256, 128, 64]):\n",
    "        x = layers.UpSampling2D(interpolation='bilinear', name=f'up{i}')(x) \n",
    "        x = cbl(x, f, k=3, name=f'gen_c{i+1}')\n",
    "        x = adain(x, t_in, f'gen_adain{i+1}a')\n",
    "        x = cbl(x, f, use_residual=True, name=f'gen_r{i+1}')\n",
    "        x = adain(x, t_in, f'gen_adain{i+1}b')\n",
    "\n",
    "    # Multi-scale output for better detail\n",
    "    out = layers.Conv2D(3, 3, padding='same', activation='tanh', name='toRGB')(x)\n",
    "    \n",
    "    return models.Model([s_in, t_in], out, name='Generator')\n",
    "\n",
    "def build_discriminator():\n",
    "    inp = layers.Input([IMG, IMG, 3])\n",
    "    \n",
    "    # More capacity with residual blocks\n",
    "    x = cbl(inp, 64, name='d_c1')\n",
    "    x = cbl(x, 64, use_residual=True, name='d_r1')\n",
    "    \n",
    "    x = cbl(x, 128, s=2, name='d_c2')             # 128×128\n",
    "    x = cbl(x, 128, use_residual=True, name='d_r2')\n",
    "    \n",
    "    x = cbl(x, 256, s=2, name='d_c3')             # 64×64\n",
    "    x = cbl(x, 256, use_residual=True, name='d_r3')\n",
    "    \n",
    "    x = cbl(x, 512, s=2, name='d_c4')             # 32×32\n",
    "    x = cbl(x, 512, use_residual=True, name='d_r4')\n",
    "    \n",
    "    # Add spectral normalization for stability\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='leaky_relu', name='d_fc')(x)\n",
    "    out = layers.Dense(1, name='d_out')(x)\n",
    "    \n",
    "    return models.Model(inp, out, name='Discriminator')\n",
    "\n",
    "class SAE(models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.E = build_encoder()\n",
    "        self.G = build_generator()\n",
    "        self.D = build_discriminator()\n",
    "        self.vgg = build_vgg_features()\n",
    "        \n",
    "        self.bce = losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.l1 = losses.MeanAbsoluteError()\n",
    "        self.l2 = losses.MeanSquaredError()\n",
    "    \n",
    "    def compile(self, g_opt, d_opt):\n",
    "        super().compile()\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "    \n",
    "    def perceptual_loss(self, real, fake):\n",
    "        # Convert from [-1,1] to VGG input format\n",
    "        real = (real + 1) * 127.5\n",
    "        fake = (fake + 1) * 127.5\n",
    "        \n",
    "        # Preprocess for VGG\n",
    "        real = applications.vgg19.preprocess_input(real)\n",
    "        fake = applications.vgg19.preprocess_input(fake)\n",
    "        \n",
    "        # Get features\n",
    "        real_features = self.vgg(real)\n",
    "        fake_features = self.vgg(fake)\n",
    "        \n",
    "        # Calculate content loss (feature reconstruction)\n",
    "        p_loss = 0\n",
    "        for r, f in zip(real_features, fake_features):\n",
    "            p_loss += self.l2(r, f)\n",
    "        \n",
    "        return p_loss / len(real_features)\n",
    "    \n",
    "    def style_loss(self, real, fake):\n",
    "        # Convert from [-1,1] to VGG input format\n",
    "        real = (real + 1) * 127.5\n",
    "        fake = (fake + 1) * 127.5\n",
    "        \n",
    "        # Preprocess for VGG\n",
    "        real = applications.vgg19.preprocess_input(real)\n",
    "        fake = applications.vgg19.preprocess_input(fake)\n",
    "        \n",
    "        # Get features\n",
    "        real_features = self.vgg(real)\n",
    "        fake_features = self.vgg(fake)\n",
    "        \n",
    "        # Calculate style loss (Gram matrix difference)\n",
    "        s_loss = 0\n",
    "        for r, f in zip(real_features, fake_features):\n",
    "            # Calculate Gram matrices\n",
    "            r_gram = self._gram_matrix(r)\n",
    "            f_gram = self._gram_matrix(f)\n",
    "            s_loss += self.l2(r_gram, f_gram)\n",
    "        \n",
    "        return s_loss / len(real_features)\n",
    "    \n",
    "    def _gram_matrix(self, x):\n",
    "        # Reshape to [batch_size, height*width, channels]\n",
    "        features = tf.reshape(x, (tf.shape(x)[0], -1, tf.shape(x)[-1]))\n",
    "        \n",
    "        # Calculate Gram matrix\n",
    "        gram = tf.matmul(features, features, transpose_a=True)\n",
    "        \n",
    "        # Normalize\n",
    "        n = tf.cast(tf.shape(features)[1], tf.float32)\n",
    "        return gram / n\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        x, y = tf.split(batch, 2)               # x=first half, y=second half\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            sx, tx = self.E(x)\n",
    "            sy, ty = self.E(y)\n",
    "            \n",
    "            x_rec = self.G([sx, tx])\n",
    "            x_swap = self.G([sx, ty])\n",
    "\n",
    "            real = tf.concat([x, y], 0)\n",
    "            fake = tf.concat([x_rec, x_swap], 0)\n",
    "\n",
    "            # Discriminator outputs\n",
    "            d_real = self.D(real)\n",
    "            d_fake = self.D(fake)\n",
    "\n",
    "            # Discriminator loss\n",
    "            d_loss = self.bce(tf.ones_like(d_real), d_real) + \\\n",
    "                     self.bce(tf.zeros_like(d_fake), d_fake)\n",
    "\n",
    "            # Generator losses\n",
    "            g_adv = self.bce(tf.ones_like(d_fake), d_fake)\n",
    "            g_l1 = self.l1(x, x_rec)\n",
    "            \n",
    "            # Perceptual and style losses\n",
    "            p_loss = self.perceptual_loss(x, x_rec)\n",
    "            s_loss = self.style_loss(x, x_rec)\n",
    "            \n",
    "            # Combined generator loss\n",
    "            g_loss = g_adv + LAMBDA_L1 * g_l1 + LAMBDA_PERCEP * p_loss + LAMBDA_STYLE * s_loss\n",
    "\n",
    "        # Update discriminator\n",
    "        d_grads = tape.gradient(d_loss, self.D.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(d_grads, self.D.trainable_variables))\n",
    "\n",
    "        # Update encoder and generator\n",
    "        eg_vars = self.E.trainable_variables + self.G.trainable_variables\n",
    "        eg_grads = tape.gradient(g_loss, eg_vars)\n",
    "        self.g_opt.apply_gradients(zip(eg_grads, eg_vars))\n",
    "\n",
    "        return {\n",
    "            \"d_loss\": d_loss, \n",
    "            \"g_loss\": g_loss, \n",
    "            \"recon\": g_l1,\n",
    "            \"perceptual\": p_loss,\n",
    "            \"style\": s_loss\n",
    "        }\n",
    "\n",
    "def load_custom(path):\n",
    "    \"\"\"Load and preprocess an image.\"\"\"\n",
    "    img = tf.io.read_file(str(path))\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, [IMG, IMG])\n",
    "    img = (img / 127.5) - 1.0\n",
    "    return img[None, ...]\n",
    "\n",
    "# Convert from [-1,1] to [0,1] range\n",
    "def to01(x): \n",
    "    return tf.clip_by_value((x + 1) * 0.5, 0, 1)\n",
    "\n",
    "# Create mosaic visualization\n",
    "def make_mosaic(imgs, rows=3, cols=2):\n",
    "    imgs = [to01(i).numpy().squeeze() for i in imgs]\n",
    "    h, w, _ = imgs[0].shape\n",
    "    canvas = np.zeros((rows*h, cols*w, 3), np.float32)\n",
    "    k = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            canvas[r*h:(r+1)*h, c*w:(c+1)*w] = imgs[k]; k += 1\n",
    "    return canvas\n",
    "\n",
    "class TensorBoardCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, sample_ds, reference_images=None, log_dir=None):\n",
    "        super().__init__()\n",
    "        self.sample_batch = next(iter(sample_ds.take(1)))\n",
    "        self.history = []\n",
    "        \n",
    "        # Create TensorBoard writer\n",
    "        log_dir = log_dir or f\"logs/fit/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "        self.tb_writer = tf.summary.create_file_writer(log_dir)\n",
    "        \n",
    "        # Load reference images if provided\n",
    "        self.has_references = False\n",
    "        if reference_images:\n",
    "            self.img_a = load_custom(reference_images[0])\n",
    "            self.img_b = load_custom(reference_images[1])\n",
    "            self.has_references = True\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Track losses for plotting\n",
    "        self.history.append(logs)\n",
    "        \n",
    "        # Log metrics to main TensorBoard log directory\n",
    "        metrics_writer = tf.summary.create_file_writer(self.log_dir)\n",
    "        with metrics_writer.as_default():\n",
    "            for name, value in logs.items():\n",
    "                tf.summary.scalar(name, value, step=epoch)\n",
    "        \n",
    "        # Process batch samples\n",
    "        try:\n",
    "            img_a = self.sample_batch[:1]\n",
    "            img_b = self.sample_batch[1:2]\n",
    "            \n",
    "            s_a, t_a = self.model.E(img_a)\n",
    "            s_b, t_b = self.model.E(img_b)\n",
    "            \n",
    "            recon_a = self.model.G([s_a, t_a])\n",
    "            recon_b = self.model.G([s_b, t_b])\n",
    "            swap_ab = self.model.G([s_a, t_b])\n",
    "            swap_ba = self.model.G([s_b, t_a])\n",
    "            \n",
    "            # Create mosaic\n",
    "            row1 = tf.concat([img_a, img_b], axis=2)   #width\n",
    "            row2 = tf.concat([recon_a, recon_b], axis=2)\n",
    "            row3 = tf.concat([swap_ab, swap_ba], axis=2)\n",
    "            big = tf.concat([row1, row2, row3], axis=1)  #height\n",
    "            big = self._to01(big)[0]\n",
    "            \n",
    "            # Logging\n",
    "            with self.tb_writer.as_default():\n",
    "                tf.summary.image(\"Batch_Samples\", big[None, ...], step=epoch)\n",
    "                \n",
    "                ssim_a = tf.image.ssim(self._to01(img_a), self._to01(recon_a), max_val=1.0).numpy()[0]\n",
    "                ssim_b = tf.image.ssim(self._to01(img_b), self._to01(recon_b), max_val=1.0).numpy()[0]\n",
    "                \n",
    "                tf.summary.scalar(\"SSIM_A\", ssim_a, step=epoch)\n",
    "                tf.summary.scalar(\"SSIM_B\", ssim_b, step=epoch)\n",
    "                \n",
    "            print(f\"Epoch {epoch}: Saved batch sample images to TensorBoard\")\n",
    "            \n",
    "            # Process reference images if available\n",
    "            if self.has_references:\n",
    "                ref_s_a, ref_t_a = self.model.E(self.img_a)\n",
    "                ref_s_b, ref_t_b = self.model.E(self.img_b)\n",
    "                \n",
    "                ref_recon_a = self.model.G([ref_s_a, ref_t_a])\n",
    "                ref_recon_b = self.model.G([ref_s_b, ref_t_b])\n",
    "                ref_swap_ab = self.model.G([ref_s_a, ref_t_b])\n",
    "                ref_swap_ba = self.model.G([ref_s_b, ref_t_a])\n",
    "                \n",
    "                # Create reference mosaic\n",
    "                ref_row1 = tf.concat([self.img_a, self.img_b], axis=2)\n",
    "                ref_row2 = tf.concat([ref_recon_a, ref_recon_b], axis=2)\n",
    "                ref_row3 = tf.concat([ref_swap_ab, ref_swap_ba], axis=2)\n",
    "                ref_big = tf.concat([ref_row1, ref_row2, ref_row3], axis=1)\n",
    "                ref_big = self._to01(ref_big)[0]\n",
    "                \n",
    "                # Log\n",
    "                with self.tb_writer.as_default():\n",
    "                    tf.summary.image(\"Reference_Images\", ref_big[None, ...], step=epoch)\n",
    "                    \n",
    "                    # Log reference SSIM metrics\n",
    "                    ref_ssim_a = tf.image.ssim(self._to01(self.img_a), self._to01(ref_recon_a), max_val=1.0).numpy()[0]\n",
    "                    ref_ssim_b = tf.image.ssim(self._to01(self.img_b), self._to01(ref_recon_b), max_val=1.0).numpy()[0]\n",
    "                    \n",
    "                    tf.summary.scalar(\"Ref_SSIM_A\", ref_ssim_a, step=epoch)\n",
    "                    tf.summary.scalar(\"Ref_SSIM_B\", ref_ssim_b, step=epoch)\n",
    "                \n",
    "                print(f\"Epoch {epoch}: Saved reference images to TensorBoard\")\n",
    "            \n",
    "            self.tb_writer.flush()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating TensorBoard images: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "ckpt_dir = pathlib.Path(\"checkpoints\")\n",
    "ckpt_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#LOG_ROOT = \"/root/tf-logs\"\n",
    "LOG_ROOT = \"\"\n",
    "#os.makedirs(LOG_ROOT, exist_ok=True) \n",
    "\n",
    "run_id  = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(LOG_ROOT, run_id)\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir      = log_dir,\n",
    "    update_freq  = \"batch\",   # log for every batch\n",
    "    histogram_freq = 0\n",
    ")\n",
    "\n",
    "\n",
    "# Training\n",
    "num_epochs=60\n",
    "sae = SAE()\n",
    "sae.compile(\n",
    "    g_opt=tf.keras.optimizers.Adam(1e-4, beta_1=0.5),  # Lower learning rate for stability\n",
    "    d_opt=tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    ")\n",
    "\n",
    "reference_images = [\"A.png\", \"B.png\"]\n",
    "\n",
    "sample_ds = dataset.take(1)\n",
    "callbacks = [\n",
    "    # TensorBoard callback with reference images\n",
    "    TensorBoardCallback(\n",
    "        sample_ds=sample_ds,\n",
    "        reference_images=reference_images,\n",
    "        log_dir=log_dir\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(ckpt_dir / \"improved_sae_{epoch:02d}.ckpt\"),\n",
    "        save_weights_only=True,\n",
    "        save_freq=5 * (len(files) // BATCH) if 'files' in globals() else 5 * 100,  # Save every 5 epochs\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        update_freq=\"batch\"\n",
    "    )\n",
    "]\n",
    "    \n",
    "num_steps = len(files) // BATCH if 'files' in globals() else 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "sae.fit(\n",
    "    dataset, \n",
    "    epochs=num_epochs, \n",
    "    steps_per_epoch=num_steps, \n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0ed4c-07b9-469f-a7c2-af79a4c6223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom(path):\n",
    "    \"\"\"Load and preprocess an image.\"\"\"\n",
    "    img  = tf.io.read_file(str(path))\n",
    "    img  = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img  = tf.image.resize(img, [IMG, IMG])\n",
    "    img  = (img / 127.5) - 1.0      # →  [-1, 1]\n",
    "    return img[None, ...]           # add batch dim (1, H, W, C)\n",
    "\n",
    "def to01(x): \n",
    "    \"\"\"Convert from [-1,1] to [0,1] range.\"\"\"\n",
    "    return tf.clip_by_value((x + 1) * 0.5, 0, 1)\n",
    "\n",
    "# Create model\n",
    "sae = SAE()\n",
    "sae.compile(\n",
    "    g_opt=tf.keras.optimizers.Adam(1e-4, beta_1=0.5),\n",
    "    d_opt=tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    ")\n",
    "\n",
    "checkpoint_dir = \"./checkpoints/\"\n",
    "checkpoint_name = \"improved_sae_115\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"{checkpoint_name}.ckpt\")\n",
    "\n",
    "# Check if checkpoint exists before loading\n",
    "if os.path.exists(f\"{checkpoint_path}.index\"):\n",
    "    sae.load_weights(checkpoint_path)\n",
    "    print(f\"Model loaded from checkpoint: {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "    print(f\"Available checkpoints in {checkpoint_dir}:\")\n",
    "    for file in os.listdir(checkpoint_dir):\n",
    "        if file.endswith(\".index\"):\n",
    "            print(f\"  - {file.replace('.index', '')}\")\n",
    "    \n",
    "    # Try to find any available checkpoint\n",
    "    available_checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".index\")]\n",
    "    if available_checkpoints:\n",
    "        latest_ckpt = os.path.join(checkpoint_dir, available_checkpoints[-1].replace(\".index\", \"\"))\n",
    "        print(f\"\\nAttempting to load the latest available checkpoint: {latest_ckpt}\")\n",
    "        sae.load_weights(latest_ckpt)\n",
    "        print(f\"Successfully loaded: {latest_ckpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21604d31-8f22-4b21-ad46-bcae43d16ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load images\n",
    "a_path = Path(\"A.png\")\n",
    "b_path = Path(\"B.png\")\n",
    "img_a, img_b = load_custom(a_path), load_custom(b_path)\n",
    "\n",
    "# Encode, reconstruct, swap\n",
    "s_a, t_a = sae.E(img_a)\n",
    "s_b, t_b = sae.E(img_b)\n",
    "recon_a = sae.G([s_a, t_a])\n",
    "recon_b = sae.G([s_b, t_b])\n",
    "swap_ab = sae.G([s_a, t_b])   # A structure, B texture\n",
    "swap_ba = sae.G([s_b, t_a])   # B structure, A texture\n",
    "\n",
    "\n",
    "images_to_save = {\n",
    "    \"recon_a.png\": recon_a,\n",
    "    \"recon_b.png\": recon_b,\n",
    "    \"swap_ab.png\": swap_ab,\n",
    "    \"swap_ba.png\": swap_ba\n",
    "}\n",
    "\n",
    "output_dir = Path(\".\")\n",
    "print(f\"Saving images to {output_dir}...\")\n",
    "for filename, tensor in images_to_save.items():\n",
    "    try:\n",
    "        img_01 = to01(tensor)\n",
    "        img_np = img_01.numpy()\n",
    "        img_squeezed = img_np.squeeze()\n",
    "\n",
    "        save_path = output_dir / filename\n",
    "        \n",
    "        plt.imsave(save_path, img_squeezed)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {filename}: {e}\")\n",
    "\n",
    "print(\"Finished saving images.\")\n",
    "def make_mosaic(imgs, rows=3, cols=2):\n",
    "    imgs = [to01(i).numpy().squeeze() for i in imgs]\n",
    "    h, w, _ = imgs[0].shape\n",
    "    canvas = np.zeros((rows*h, cols*w, 3), np.float32)\n",
    "    k = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            canvas[r*h:(r+1)*h, c*w:(c+1)*w] = imgs[k]; k += 1\n",
    "    return canvas\n",
    "\n",
    "mosaic = make_mosaic([\n",
    "    img_a, img_b,\n",
    "    recon_a, recon_b,\n",
    "    swap_ab, swap_ba\n",
    "])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.imshow(mosaic)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Add labels\n",
    "labels = [\"Original A\", \"Original B\", \n",
    "          \"Reconstructed A\", \"Reconstructed B\",\n",
    "          \"A structure + B texture\", \"B structure + A texture\"]\n",
    "\n",
    "positions = [(0.25, 0.05), (0.75, 0.05),\n",
    "             (0.25, 0.38), (0.75, 0.38),\n",
    "             (0.25, 0.71), (0.75, 0.71)]\n",
    "\n",
    "# Calculate and display SSIM metrics for reconstructions\n",
    "ssim_a = tf.image.ssim(to01(img_a), to01(recon_a), max_val=1.0).numpy()[0]\n",
    "ssim_b = tf.image.ssim(to01(img_b), to01(recon_b), max_val=1.0).numpy()[0]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5ccf2-51c0-4796-910a-7b3343d1d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Interpolate between texture codes of images A and B.\n",
    "steps = 4\n",
    "alphas = np.linspace(0, 1, steps)\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Interpolate texture vectors\n",
    "    t_mix = t_a * (1 - alpha) + t_b * alpha\n",
    "    # Generate using fixed structure with interpolated texture\n",
    "    img = sae.G([s_a, t_mix])\n",
    "    results.append(img)\n",
    "\n",
    "# Visualize results\n",
    "fig = plt.figure(figsize=(steps*3, 4))\n",
    "for i, img in enumerate(results):\n",
    "    plt.subplot(1, steps, i+1)\n",
    "    plt.imshow(to01(img)[0])\n",
    "    plt.title(f\"α={alphas[i]:.2f}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Texture Interpolation (Structure A with textures from A→B)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"interpolation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d3c5c-7f56-46af-972b-a44b0b47fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "a_path = Path(\"A.png\")\n",
    "b_path = Path(\"B.png\")\n",
    "img_a, img_b = load_custom(a_path), load_custom(b_path)\n",
    "\n",
    "# Encode, reconstruct, swap\n",
    "s_a, t_a = sae.E(img_a)\n",
    "s_b, t_b = sae.E(img_b)\n",
    "recon_a = sae.G([s_a, t_a])   # B structure, A texture\n",
    "swap_ab = sae.G([s_a, t_b])   # A structure, B texture\n",
    "print(\"Generation complete.\")\n",
    "\n",
    "\n",
    "images_to_plot = [img_a, img_b, recon_a, swap_ab]\n",
    "titles = [\n",
    "    \"Structure Image (A)\",\n",
    "    \"Texture Image (B)\",\n",
    "    \"Reconstructed Structure (A)\",\n",
    "    \"Style Transferred (A struct, B tex)\"\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(\"Generating 2x2 plot...\")\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(images_to_plot):\n",
    "        img_display = to01(images_to_plot[i]).numpy().squeeze()\n",
    "        ax.imshow(img_display)\n",
    "        ax.set_title(titles[i], fontsize=12)\n",
    "        ax.axis(\"off\")\n",
    "    else:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout(pad=1.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "print(\"Plot displayed.\")\n",
    "\n",
    "fig.savefig(\"results.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
